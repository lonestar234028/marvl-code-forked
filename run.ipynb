{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "H5=\"/vc_data/users/taoli1/topic/69b4d8dd2421c858a7f5d323299e99b1/b3af07f6-8898-4470-8090-5783484ddb68\"\n",
    "LMDB=\"/vc_data/users/taoli1/topic/69b4d8dd2421c858a7f5d323299e99b1/marvl-en_US.UTF-8_boxes36.lmdb\"\n",
    "\n",
    "# source /opt/conda/bin/activate\n",
    "#  -- feature processing --\n",
    "\n",
    "# python feature_extraction/h5_to_lmdb.py --h5 H5 --lmdb LMDB\n",
    "\n",
    "TASK=12\n",
    "MODEL=\"ctrl_xuniter\"\n",
    "MODEL_CONFIG=\"./volta/config/ctrl_xuniter_base.json\"\n",
    "TRTASK=\"NLVR2\"\n",
    "TETASK=\"MaRVLzh\"\n",
    "TASKS_CONFIG=\"./volta/config_tasks/xling_test_marvl.yml\"\n",
    "TEXT_PATH=\"./data/zh/annotations_machine-translate/marvl-zh_gmt.jsonl\"\n",
    "FEAT_PATH={LMDB}\n",
    "PRETRAINED=\"/vc_data/users/taoli1/topic/540b6cbb8ab82b5e08a077dc9ddce033/ofa.bin\"\n",
    "OUTPUT_DIR=\"C:\\\\Users\\\\taoli1\\code\\MultiModal\\ofa_proj\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\taoli1\\code\\MultiModal\\ofa_proj\\marvl-code-forked\\volta\\eval_task_ofa_improved.py\", line 29, in <module>\n",
      "    from volta.datasets.from_dataset import get_dataset\n",
      "  File \"c:\\Users\\taoli1\\code\\MultiModal\\ofa_proj\\marvl-code-forked\\volta\\volta\\datasets\\from_dataset.py\", line 2, in <module>\n",
      "    from torchvision import transforms\n",
      "  File \"c:\\Users\\taoli1\\Anaconda3\\envs\\hello-june\\lib\\site-packages\\torchvision\\__init__.py\", line 2, in <module>\n",
      "    from torchvision import datasets\n",
      "  File \"c:\\Users\\taoli1\\Anaconda3\\envs\\hello-june\\lib\\site-packages\\torchvision\\datasets\\__init__.py\", line 9, in <module>\n",
      "    from .fakedata import FakeData\n",
      "  File \"c:\\Users\\taoli1\\Anaconda3\\envs\\hello-june\\lib\\site-packages\\torchvision\\datasets\\fakedata.py\", line 3, in <module>\n",
      "    from .. import transforms\n",
      "  File \"c:\\Users\\taoli1\\Anaconda3\\envs\\hello-june\\lib\\site-packages\\torchvision\\transforms\\__init__.py\", line 1, in <module>\n",
      "    from .transforms import *\n",
      "  File \"c:\\Users\\taoli1\\Anaconda3\\envs\\hello-june\\lib\\site-packages\\torchvision\\transforms\\transforms.py\", line 17, in <module>\n",
      "    from . import functional as F\n",
      "  File \"c:\\Users\\taoli1\\Anaconda3\\envs\\hello-june\\lib\\site-packages\\torchvision\\transforms\\functional.py\", line 5, in <module>\n",
      "    from PIL import Image, ImageOps, ImageEnhance, PILLOW_VERSION\n",
      "ImportError: cannot import name 'PILLOW_VERSION' from 'PIL' (c:\\Users\\taoli1\\Anaconda3\\envs\\hello-june\\lib\\site-packages\\PIL\\__init__.py)\n"
     ]
    }
   ],
   "source": [
    "# this is for windows cmd\n",
    "!python volta/eval_task_ofa_improved.py \\\n",
    "        --bert_model \"xlm-roberta-base\" \\\n",
    "        --config_file {MODEL_CONFIG} \\\n",
    "        --from_pretrained {PRETRAINED} \\\n",
    "        --val_annotations_jsonpath {TEXT_PATH} --val_features_lmdbpath {FEAT_PATH} \\\n",
    "        --tasks_config_file {TASKS_CONFIG} --task {TASK} --split test \\\n",
    "        --output_dir {OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading_annotations: \n",
      "{'image_id_0': '82-6', 'image_id_1': '82-1', 'question_id': 0, 'sentence': 'The picture on the left has several pencils of different colors, and the picture on the right has only one pencil.', 'labels': [0], 'scores': [1.0]}\n"
     ]
    }
   ],
   "source": [
    "from volta.volta.datasets.form_dataset_ofa import get_dataset\n",
    "ds = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82-6\n",
      "82-1\n"
     ]
    }
   ],
   "source": [
    "print(ds[0]['image_id_0'])\n",
    "print(ds[0]['image_id_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taoli1\\AppData\\Local\\Temp\\ipykernel_33540\\940585970.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  save_image(torch.tensor(img), 'bin_img.jpg')\n"
     ]
    }
   ],
   "source": [
    "from torchvision.utils import save_image\n",
    "import torch\n",
    "img = ds[0]['picture']\n",
    "save_image(torch.tensor(img), 'bin_img.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('aug')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e96e06abe4d7db54fd176c6b1bd82fab86976df376cb9673d7ec41dfd0ca7ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
